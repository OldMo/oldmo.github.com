---
layout: post
title: "PHP获取微信公众号文章"
description: ""
category: IT在路上
tags: 
---

###实现功能
最近想要完成一个获取微信公众号历史文章的功能，搜索了一下，发现直接通过脚本去爬取微信平台还是比较有难度的，后来发现搜狗已经实现了这个功能，搜狗微信搜索可以查找到基本上所有公众号的历史文章，因此考虑借助搜狗来完成文章的获取，后来发现还是有弊端的，搜狗上只能获取10页的文章，即最近的100篇。先凑合着用了，获取文章也变为网页信息爬取了。  

###网络请求获取
进入搜狗微信搜索，输入公众号，可以进入该公众号的文章列表页，如：[http://weixin.sogou.com/gzh?openid=oIWsFt-4lR2-450wfo60XXrtklqY](http://weixin.sogou.com/gzh?openid=oIWsFt-4lR2-450wfo60XXrtklqY)
刚开始想得很简单，以为直接通过这个url进行爬取就可以获取所有的文章内容，后来尝试了一下，发现并不是如此。搜狗上的微信文章的获取是需要提交json请求完成的，而且也是以json的形式返回的，因此首先要弄清楚发送的是什么样的网络请求，我是通过Firefox的firebug插件来查看网络请求的，如下：    
![网络请求](http://www.mojiaqin.cn/images/2015/0707/firebug1.png)

可以看到，是通过如下的一个链接进行文章的获取请求，具体如下：    
![网络请求](http://www.mojiaqin.cn/images/2015/0707/firebug2.png)  


请求中字段代表的意义如下：

- cb：固定为“sogou.weixin.gzhcb”
- openid：根据公众号来填
- eqs： 对openid进行了加密操作, 参数都是固定
- ekv：貌似填4就可以了
- page：页码，默认每页显示10条，需要查看更多的时候用它来翻页
- t：时间参数，貌似并没有什么O用

###返回信息形式
获取此链接后，通过发送该请求就可以得到文章信息，以json形式返回信息，部分信息如下所示，里边的“items”项包含了我们需要的数据，用xml封装，如果先要将获取到信息想直接显示到浏览器，通过使用echo来打印是无法实现的，我是通过写入文件来查看的。

	sogou.weixin.gzhcb({"page":1,"items":["<?xml version=\"1.0\" encoding=\"gbk\"?><DOCUMENT><docid><\/docid><item> <key><![CDATA[http://mp.weixin.qq.com/]]><\/key><tplid><![CDATA[555]]><\/tplid><classid>11002601<\/classid> <display> <docid>ab735a258a90e8e1-6bee54fcbd896b2a-6deb4d71ff08347f1929b25ff173e5de<\/docid> <tplid>550<\/tplid><title><![CDATA[【突发】一艘载有400余人的客轮在长江沉没  搜救正在进行]]><\/title><url><![CDATA[http://mp.weixin.qq.com/s?__biz=MjM5MjAxNDM4MA==&mid=216655341&idx=1&sn=fd0396cb30456a310475ff351e9fa975&3rd=MzA3MDU4NTYzMw==&scene=6#rd]]><\/url><title1><![CDATA[【突发】一艘载有400余人的客轮在长江沉没  搜救正在进行]]><\/title1><imglink>...

###处理方式
items里有10条xml段，每一条xml段代表了一篇文章信息，可以先提取items的信息，然后分割每段xml，再调用PHP处理xml文件的方法simplexml_load_string()将信息转换成xml来处理，由于刚开始处理时我没有注意到xml信息显示到浏览器会出现的问题，一直无法将获取的信息显示到浏览器中，所以在获取到信息后，我又用htmlspecialchars()对字符串进行了html字符的转码处理，使得信息可以显示到浏览器，但是，正常的'<','>'等符号都变成了编码形式，导致直接转换成xml形式来处理遇到了问题，所以，在提取信息时，我是采用正则表达式来完成的，后来发现，正则确实还比较简单一些。  

###代码实现
下面是实现文章信息获取的代码：

	<?php
	@header('Content-type: text/html;charset=UTF-8');
    
	echo "开始爬取微信文章......";
	
	$count = 0;
	/**********
	     数据库操作
	*****/
	$myconn=mysql_connect("localhost","root","root");
	mysql_query("set names 'utf8'"); //指定写入编码
	mysql_select_db("article",$myconn);
	    
	for($page = 1; $page <= 10; $page++)
	{
	     $url = "http://weixin.sogou.com/gzhjs?cb=sogou.weixin.gzhcb&openid=oIWsFt-4lR2-450wfo60XXrtklqY&eqs=cls2o4dgqyYXowtDdJkJRuTSG9PcwNTSF%2B8KujiGLML7bPu3Nc9gcwQOZa6WL7Ob44OuT&ekv=7&page=".$page."&t=1435421383410";
	     $ch = curl_init();
	     curl_setopt ($ch, CURLOPT_URL, $url);
	     curl_setopt ($ch, CURLOPT_RETURNTRANSFER, 1);
	     curl_setopt ($ch, CURLOPT_CONNECTTIMEOUT,100);
	    
	     $content = curl_exec($ch);
	
	     $s = str_replace("\\","",$content);  //去掉转义符
	
	     $arr = explode("\",\"",$s);         //分割xml段
	
	     $m = 0;
	    
	     foreach($arr as $value){
	          preg_match_all("/\<title\>\<!\[CDATA\[(.*)\]\]\>\<\/title\>/",$value,$titleArea);//匹配标题
	          $title = current($titleArea[1]);
	         
	          preg_match_all("/\<url\>\<!\[CDATA\[(.*)\]\]\>\<\/url\>/",$value,$urlArea);//匹配文章url
	          $url = current($urlArea[1]);
	         
	          preg_match_all("/\<imglink\>\<!\[CDATA\[(.*)\]\]\>\<\/imglink\>/",$value,$imglinkArea);//匹配图片url
	          $imglink = current($imglinkArea[1]);
	         
	          preg_match_all("/\<content168\>\<!\[CDATA\[(.*)\]\]\>\<\/content168\>/",$value,$contentArea);//匹配文章内容
	          $content = current($contentArea[1]);
	         
	          preg_match_all("/\<date\>\<!\[CDATA\[(.*)\]\]\>\<\/date\>/",$value,$dateArea);//匹配文章发表时间
	          $date = current($dateArea[1]);
	         
	          $strSql="insert into weixinarticles(title,url,imglink,content,postday) values('".$title."','".$url."','".$imglink."','".$content."','".$date."')";
	          $result=mysql_query($strSql,$myconn);
	         
	          $count++;
	         
	     }
	    
	     echo "爬取结束!,共抓取到".$count."篇文章！";
	}
	//关闭对数据库的连接
	  mysql_close($myconn);
	
	?>
